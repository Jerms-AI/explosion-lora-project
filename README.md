# ğŸ’£ Explosion LORA Project

This repo documents a hands-on journey into training a custom LoRA (Low-Rank Adaptation) for explosions, using ComfyUI with a **creatively merged SDXL model** and Flux models, plus custom enhancement nodes built from scratch.

---

## ğŸš€ Project Structure

```
explosion-lora-project/
â”œâ”€â”€ custom_nodes/
â”‚   â””â”€â”€ image_manipulation_tools/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ enhance_detail_node.py
â”‚       â””â”€â”€ README.md   â† Docs for Enhance Detail Node âœ…
â”œâ”€â”€ comfyui_workflows/
â”‚   â””â”€â”€ explosion_generation.json
â”œâ”€â”€ training/
â”‚   â””â”€â”€ train_lora_sdxl.py
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md  â† You are here
â””â”€â”€ requirements.txt
```

---

## ğŸ§  Custom Nodes

Weâ€™re extending ComfyUI with simple but powerful image processing tools. Currently includes:

### ğŸ”¹ [Enhance Detail Node](custom_nodes/image_manipulation_tools/README.md)
Boost image detail using OpenCVâ€™s `detailEnhance`.  
This node:
- Handles both NumPy arrays and PyTorch tensors
- Outputs a tensor for seamless ComfyUI integration
- Lets you tweak `detail_strength` and `smoothness` to control clarity and texture

Use it before training LoRA datasets or final renders to sharpen image fidelity.

More nodes coming soon (contrast, blur, mask tweaks, etc). Each one will live in its own modular Python file with docs.

---

## ğŸ§ª Dataset Creation Workflows

Inside `comfyui_workflows/explosion_generation.json`, you'll find a node-based image creation pipeline combining:
- A creatively merged SDXL model + Flux fusion
- Custom enhancement passes
- High-quality explosion image generation

This is experimental and will be refactored as the project progresses.

---

## ğŸ¯ Training

The `training/train_lora_sdxl.py` script will eventually contain a clean LoRA fine-tuning workflow using ğŸ¤— diffusers or direct PyTorch.

We're bypassing GUI tools like `kohya_ss` for full control.

---

## ğŸ§¾ Dataset Creation Guidelines

### ğŸ“ Resolution Tips
- **Generate high-res images** (e.g. 2048x2048) to retain visual clarity
- **Crop or resize** to 1024x1024 (or 896x896) for training â€” especially for SDXL
- Use full-res versions for showcasing or post-training super-resolution

### ğŸ¨ Diversity for Smarter Models
Introduce variety in:
- **Composition**: close-ups, wide shots, centered, off-angle
- **Lighting**: natural, cinematic, backlit, moody
- **Color grading**: warm explosions, cool explosions, desaturated
- **Environment**: explosions in urban, forest, desert, water, sci-fi
- **Style**: hyperrealistic, painterly, vintage, surreal

### ğŸ“± Vertical Framing Consideration
For social platforms (Instagram, TikTok, etc.):
- 9:16 aspect ratio (e.g. 1056x1888) looks great on mobile
- Nodes like *Flux Resolution Calc* can assist with intelligent cropping
- Output at 2K and downscale to 9:16 as needed for punchy visuals

The goal is to capture the aesthetic *and* functional diversity that teaches your model how to generalize â€” not just memorize.

---

## ğŸ‘¤ Author
Created by [jerms-ai](https://github.com/jerms-ai)

Project purpose: To create powerful aesthetic datasets, learn fine-tuning techniques, and show off technical artistry with custom ComfyUI tooling.

---

## ğŸ“¸ Demo Images
Coming soon...

Want to contribute or follow along? Watch this space â€” or fork and start enhancing your own images!

